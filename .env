# ==================== API CONFIGURATION ====================
API_HOST=0.0.0.0
API_PORT=8000

# ==================== LANGCHAIN / LLM CONFIGURATION ====================
# LLM Provider: "anthropic" , "openai" or "gemini"
LLM_PROVIDER=gemini  # Default to Gemini, fallback to Anthropic if not set

# Anthropic API Key (required for Claude models)
GEMINI_API_KEY=AIzaSyBO0GlD_MCUn5vgj8RsZLyySj5MgAn9hcU

MODEL_NAME=gemini-2.0-flash

# Temperature for LLM responses (0.0 = deterministic, 1.0 = creative)
LLM_TEMPERATURE=0.3

# Maximum tokens per agent response
MAX_TOKENS=2048

# ==================== VECTOR DB CONFIGURATION ====================
# FAISS embeddings model
EMBEDDINGS_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Path to FAISS index cache
FAISS_INDEX_PATH=backend/data/faiss_index.pkl

# Number of nearest neighbors for similarity search
K_NEAREST_NEIGHBORS=5

# Minimum similarity threshold (0-1)
SIMILARITY_THRESHOLD=0.4

# ==================== RFP PROCESSING CONFIGURATION ====================
# SMM (Spec Match Metric) threshold for technical compliance (%)
SMM_COMPLIANCE_THRESHOLD=80.0

# Maximum retry iterations for technical agent
TECHNICAL_MAX_RETRIES=3

# Size tolerance relaxation per retry (mmÂ²)
SIZE_TOLERANCE_RELAXATION=10.0

# RFP qualification window (days into future)
RFP_QUALIFICATION_WINDOW_DAYS=90

# ==================== PRICING CONFIGURATION ====================
# Default profit margin multiplier
TARGET_MARGIN=1.15

# Minimum viable margin
MINIMUM_MARGIN=1.05

# ==================== LOGGING CONFIGURATION ====================
LOG_LEVEL=INFO
LOG_TO_FILE=true
LOG_FILE_PATH=logs/rfp_processing.log

# ==================== ASYNC / CONCURRENCY ====================
# Maximum concurrent RFP processing jobs
MAX_CONCURRENT_JOBS=5

# Job timeout in seconds
JOB_TIMEOUT_SECONDS=300

# ==================== CACHING ====================
# Commodity price cache TTL (seconds)
COMMODITY_CACHE_TTL=3600

# Enable query result caching
ENABLE_QUERY_CACHE=true
